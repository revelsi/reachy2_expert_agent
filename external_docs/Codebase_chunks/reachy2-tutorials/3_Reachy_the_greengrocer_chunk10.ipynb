"from PIL import Image\n",
    "img = data['left']\n",
    "Image.fromarray(img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **T_reachy_cam**\n",
    "\n",
    "Now, we need to define the T_reachy_cam. The camera frame is oriented differently from the robot frame, with the x axis to the left, the y axis down and the z axis back (as a reminder, the robot frame of reference has the x axis forward, the y axis to the left and the z axis up). Moreover, the torso camera is tilted downwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reachy2_sdk.utils.utils import invert_affine_transformation_matrix\n",
    "\n",
    "T_cam_reachy = reachy.cameras.depth.get_extrinsics()\n",
    "T_reachy_cam = invert_affine_transformation_matrix(T_cam_reachy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Labels** \n",
    "\n",
    "To know what to use as a frequency and prediction score threshold, you first need to set the labels you're gonna use to say what you want to detect. Indeed, to use IA model for object detection, it's important to find the most relevant label for the model to find the objects, and it's not always the most intuitive words. \n",
    "\n",
    "To test those, you can use directly two submodules used in Perception to see if your objects are correctly detected on your image :\n",