]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"orange ball\", \"apple\", \"white plate\", \"white bowl\"]\n",
    "yolo_predictions = yolo.infer(im=img, candidate_labels=labels, detection_threshold=0.15)\n",
    "bboxes = get_bboxes(yolo_predictions)\n",
    "img_annotated = annotator.annotate(im=img, detection_predictions=yolo_predictions)\n",
    "Image.fromarray(img_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have good labels to detect our objects. \n",
    "\n",
    "\n",
    "##### **Detection threshold & Frequency**\n",
    "\n",
    "Now that we have our labels, we can see that we also have the prediction scores on the image : that will help you set the detection threshold when you instanciate your Perception object. Here, we decide to set it to 0.2, because the oranges are detected with a low score. \n",
    "\n",
    "The frequency depends on how well your objects are detected (if they're not well detected, a higher frequency will increase the number of frames over which the model attempts detection). Here, we are going to set it to 40 because the oranges aren't detected often. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Instanciation\n",
    "\n",