"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pollen_vision.vision_models.object_detection import YoloWorldWrapper\n",
    "from pollen_vision.utils import get_bboxes\n",
    "from pollen_vision.utils import Annotator\n",
    "\n",
    "#those first labels won't be good enough\n",
    "labels = [\"orange\", \"apple\", \"plate\", \"bowl\"]\n",
    "\n",
    "yolo = YoloWorldWrapper() #allows to use the YOLO model for object detection\n",
    "annotator = Annotator() #allows to get annotated image with the detected objects\n",
    "yolo_predictions = yolo.infer(im=img, candidate_labels=labels, detection_threshold=0.15) \n",
    "bboxes = get_bboxes(yolo_predictions) #returns the bounding boxes of the detected objects\n",
    "img_annotated = annotator.annotate(im=img, detection_predictions=yolo_predictions) \n",
    "Image.fromarray(img_annotated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you could see that the oranges aren't detected as \"orange\" and may be detected as apples. We are going to try new labels to be more effective. Also, you can add adjectives to be sure not to have any false positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"orange ball\", \"apple\", \"white plate\", \"white bowl\"]\n",